{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9tObiU-qVgv"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ryansteed/ieat/blob/master/notebooks/experiments.ipynb)\n",
    "\n",
    "# Image GPT Bias\n",
    "**Image Embedding Association Test**\n",
    "\n",
    "Ryan Steed\n",
    "\n",
    "This script adapted from https://colab.research.google.com/github/apeguero1/image-gpt/blob/master/Transformers_Image_GPT.ipynb.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "lHXoubXWpiSv",
    "outputId": "57f068ab-3890-444e-92b8-1a59c84717c4"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%cd /Users/steed/caliskan/git/ieat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OoWYiUzT_lLs"
   },
   "source": [
    "## Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "DzJbEWC6Vogc",
    "outputId": "c1286597-3cf5-45d2-af5a-f34c863f52c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi #OpenAI says you need 16GB GPU for the large model, but it may work if you lower n_sub_batch on the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "WkPOYJsCTaUb",
    "outputId": "9268d5df-fc68-4de3-d17d-cf58075831d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'ieat' already exists and is not an empty directory.\n",
      "[Errno 2] No such file or directory: '/ieat'\n",
      "/Users/steed/caliskan/git/ieat\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "\n",
    "# don't share these to Github or elsewhere!\n",
    "u = \"your_username\"\n",
    "p = urllib.parse.quote(\"your_password\")\n",
    "!git clone --recurse-submodules -j8 https://$u:$p@github.com/$u/ieat.git\n",
    "%cd /ieat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "BIOr3wBHs955",
    "outputId": "e64b0e05-02c7-4c95-cafb-677b705d7707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Users/steed/caliskan/git/ieat\n",
      "Requirement already satisfied: transformers in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from ieat==1.0) (3.1.0)\n",
      "Requirement already satisfied: torch in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from ieat==1.0) (1.6.0)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from ieat==1.0) (1.18.5)\n",
      "Requirement already satisfied: matplotlib in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from ieat==1.0) (3.3.1)\n",
      "Requirement already satisfied: opencv-python in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from ieat==1.0) (4.4.0.42)\n",
      "Requirement already satisfied: tensorflow in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from ieat==1.0) (2.3.0)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from transformers->ieat==1.0) (2.24.0)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from transformers->ieat==1.0) (3.0.12)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc2 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from transformers->ieat==1.0) (0.8.1rc2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from transformers->ieat==1.0) (4.48.2)\n",
      "Requirement already satisfied: sacremoses in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from transformers->ieat==1.0) (0.0.43)\n",
      "Requirement already satisfied: packaging in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from transformers->ieat==1.0) (20.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from transformers->ieat==1.0) (2020.7.14)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from transformers->ieat==1.0) (0.1.91)\n",
      "Requirement already satisfied: future in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from torch->ieat==1.0) (0.18.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from matplotlib->ieat==1.0) (7.2.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from matplotlib->ieat==1.0) (2020.6.20)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from matplotlib->ieat==1.0) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from matplotlib->ieat==1.0) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from matplotlib->ieat==1.0) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from matplotlib->ieat==1.0) (2.8.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from tensorflow->ieat==1.0) (3.3.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from tensorflow->ieat==1.0) (1.31.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from tensorflow->ieat==1.0) (2.10.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from tensorflow->ieat==1.0) (1.6.3)\n",
      "Requirement already satisfied: gast==0.3.3 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from tensorflow->ieat==1.0) (0.3.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from tensorflow->ieat==1.0) (3.13.0)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from tensorflow->ieat==1.0) (2.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from tensorflow->ieat==1.0) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from tensorflow->ieat==1.0) (2.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from tensorflow->ieat==1.0) (1.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from tensorflow->ieat==1.0) (1.12.1)\n",
      "Requirement already satisfied: scipy==1.4.1 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from tensorflow->ieat==1.0) (1.4.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from tensorflow->ieat==1.0) (0.2.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from tensorflow->ieat==1.0) (0.35.1)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from tensorflow->ieat==1.0) (1.1.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from tensorflow->ieat==1.0) (0.10.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from requests->transformers->ieat==1.0) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from requests->transformers->ieat==1.0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from requests->transformers->ieat==1.0) (2.10)\n",
      "Requirement already satisfied: click in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from sacremoses->transformers->ieat==1.0) (7.1.2)\n",
      "Requirement already satisfied: joblib in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from sacremoses->transformers->ieat==1.0) (0.16.0)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from protobuf>=3.9.2->tensorflow->ieat==1.0) (49.6.0.post20200814)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow->ieat==1.0) (3.2.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow->ieat==1.0) (1.21.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow->ieat==1.0) (1.7.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow->ieat==1.0) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow->ieat==1.0) (0.4.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->ieat==1.0) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->ieat==1.0) (4.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->ieat==1.0) (4.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->ieat==1.0) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->ieat==1.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->ieat==1.0) (3.1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: ieat\n",
      "  Running setup.py develop for ieat\n",
      "Successfully installed ieat\n",
      "Obtaining file:///Users/steed/caliskan/git/ieat/weat\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from weat==1.0) (1.1.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from weat==1.0) (0.23.2)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from weat==1.0) (1.18.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from pandas->weat==1.0) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from pandas->weat==1.0) (2020.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from scikit-learn->weat==1.0) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from scikit-learn->weat==1.0) (0.16.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from scikit-learn->weat==1.0) (1.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/image-gpt-bias/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->weat==1.0) (1.15.0)\n",
      "Installing collected packages: weat\n",
      "  Running setup.py develop for weat\n",
      "Successfully installed weat\n"
     ]
    }
   ],
   "source": [
    "# note - you may need to restart the kernel for these installations to take effect\n",
    "!pip install -e .\n",
    "!pip install -e weat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "e0DcaUYv8LYf"
   },
   "outputs": [],
   "source": [
    "model_sizes = [\"s\", \"m\", \"l\"] #small medium large, xl not available\n",
    "model_size = \"l\"\n",
    "models_dir = \"models\"\n",
    "color_clusters_dir = \"clusters\"\n",
    "n_px = 32\n",
    "depth = 152\n",
    "width = 3\n",
    "sk = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ylcjIJcwXsFw"
   },
   "outputs": [],
   "source": [
    "# download the model - skip if already downloaded\n",
    "!python image-gpt/download.py --model {model_size} --ckpt 1000000 --clusters --download_dir {models_dir}/{model_size}\n",
    "!python image-gpt/download.py --clusters --download_dir {color_clusters_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJcpjSByxvhQ"
   },
   "source": [
    "## IATs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rv34zwKpSHSp"
   },
   "source": [
    "### Quick Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "id": "vLl9AC5nSHSp",
    "outputId": "b5c5697e-0c30-496c-db1e-91452870f5c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# igpt-logit #\n",
      "## Insect-Flower ##\n",
      "## Weapon ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-01 15:45:02,304 [85526] WARNING  root:202: [JupyterRequire] Equalities contributed 1/924 to p-value\n",
      "2020-10-01 15:45:02,420 [85526] WARNING  root:202: [JupyterRequire] Equalities contributed 1/924 to p-value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Weapon (Modern) ##\n",
      "## Native ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-01 15:45:02,648 [85526] WARNING  root:202: [JupyterRequire] Equalities contributed 2/10000 to p-value\n",
      "2020-10-01 15:45:02,752 [85526] WARNING  root:202: [JupyterRequire] Equalities contributed 1/924 to p-value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Asian ##\n",
      "## Weight ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-01 15:45:03,065 [85526] WARNING  root:202: [JupyterRequire] Equalities contributed 1/3432 to p-value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Skin-Tone ##\n",
      "## Disability ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-01 15:45:03,203 [85526] WARNING  root:202: [JupyterRequire] Equalities contributed 1/70 to p-value\n",
      "2020-10-01 15:45:03,322 [85526] WARNING  root:202: [JupyterRequire] Equalities contributed 1/924 to p-value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## President - Kennedy vs. Trump ##\n",
      "## President - B. Clinton vs. Trump ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-01 15:45:03,453 [85526] WARNING  root:202: [JupyterRequire] Equalities contributed 1/924 to p-value\n",
      "2020-10-01 15:45:03,582 [85526] WARNING  root:202: [JupyterRequire] Equalities contributed 1/924 to p-value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## President - Bush vs. Trump ##\n",
      "## President - Lincoln vs. Trump ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-01 15:45:03,715 [85526] WARNING  root:202: [JupyterRequire] Equalities contributed 1/924 to p-value\n",
      "2020-10-01 15:45:03,849 [85526] WARNING  root:202: [JupyterRequire] Equalities contributed 1/3432 to p-value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Religion ##\n",
      "## Sexuality ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-01 15:45:04,134 [85526] WARNING  root:202: [JupyterRequire] Equalities contributed 1/924 to p-value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Race ##\n",
      "## Arab-Muslim ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-01 15:45:04,418 [85526] WARNING  root:202: [JupyterRequire] Equalities contributed 1/924 to p-value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Age ##\n",
      "## Gender-Science ##\n",
      "## Gender-Career ##\n",
      "## Intersectional-Gender-Science-MF ##\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "There is no file at models/l/model.ckpt-1000000.index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4dc5b37e2c85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m results = test_all(\n\u001b[0m\u001b[1;32m      7\u001b[0m     {\n\u001b[1;32m      8\u001b[0m         \u001b[0;34m'igpt-logit'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodels_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor_clusters_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_px\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/caliskan/git/ieat/ieat/api.py\u001b[0m in \u001b[0;36mtest_all\u001b[0;34m(model_types, tests, from_cache, **test_params)\u001b[0m\n\u001b[1;32m    190\u001b[0m                                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/experiments'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \t\t\t]\n\u001b[0;32m--> 192\u001b[0;31m \t\t\teffect, p = test(\n\u001b[0m\u001b[1;32m    193\u001b[0m                                 \u001b[0;34m*\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                                 \u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/caliskan/git/ieat/ieat/api.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(X, Y, A, B, model_type, model_params, file_types, from_cache, verbose, gpu, batch_size, model, **test_params)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_dirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Extracting images from {d}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \t\tembeddings.append(extractor.extract_dir(\n\u001b[0m\u001b[1;32m     57\u001b[0m                         \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                         \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/caliskan/git/ieat/ieat/models.py\u001b[0m in \u001b[0;36mextract_dir\u001b[0;34m(self, d, file_types, batch_size, visualize, **extract_params)\u001b[0m\n\u001b[1;32m     50\u001b[0m                         \u001b[0;31m# do extraction in batches to save memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \t\t\tencs = self.extract(\n\u001b[0m\u001b[1;32m     53\u001b[0m                                 \u001b[0mimage_paths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/caliskan/git/ieat/ieat/models.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, image_paths, batch_size, output_path, gpu, visualize, **extract_kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextract_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/caliskan/git/ieat/ieat/models.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"There is no file at {self.model_path}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \t\tself.model = ImageGPT2LMHeadModel.from_pretrained(\n\u001b[1;32m    188\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: There is no file at models/l/model.ckpt-1000000.index"
     ]
    }
   ],
   "source": [
    "from ieat.api import test_all\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "results = test_all(\n",
    "    {\n",
    "        'igpt-logit': (model_size,models_dir,color_clusters_dir,n_px),\n",
    "        'igpt': (model_size,models_dir,color_clusters_dir,n_px),\n",
    "        'simclr': (depth, width, sk)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fv2Node4SHSs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(results).transpose()\n",
    "results_df.columns = [\"X\", \"Y\", \"A\", \"B\", \"d\", \"p\", \"n_t\", \"n_a\"]\n",
    "for c in results_df.columns[:4]:\n",
    "    results_df[c] = results_df[c].str.split(\"/\").str[-1]\n",
    "results_df[\"sig\"] = \"\"\n",
    "for l in [0.10, 0.05, 0.01]:\n",
    "    results_df.sig[results_df.p < l] += \"*\"\n",
    "intersectional = results_df.index.get_level_values(0).str.contains(\"Intersectional\")\n",
    "results_df[intersectional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9x5qXqGrSHSu"
   },
   "outputs": [],
   "source": [
    "# Generate latex table output\n",
    "experiments = (\n",
    "    \"Insect-Flower\",\n",
    "    \"Gender-Science\",\n",
    "    \"Gender_Career\",\n",
    "    \"Skin-Tone\",\n",
    "    \"Race\",\n",
    "    \"Weapon\",\n",
    "    \"Weapon (Modern)\",\n",
    "    \"Native\",\n",
    "    \"Asian\",\n",
    "    \"Weight\",\n",
    "    \"Religion\",\n",
    "    \"Sexuality\",\n",
    "    \"Disability\",\n",
    "    \"Arab-Muslim\",\n",
    "    \"Age\"\n",
    ")\n",
    "experiments += tuple(results_df.index.get_level_values(0)[results_df.index.get_level_values(0).str.contains(\"Intersectional\")])\n",
    "latex_df = results_df\n",
    "latex_df.index = latex_df.index.set_names([\"Test\", \"Model\"])\n",
    "latex_df = latex_df.sort_index(level=[\"Test\", \"Model\"])\n",
    "def round(s, i='{0:.2f}'):\n",
    "    return s.apply(lambda x: i.format(x)).astype(str)\n",
    "latex_df[\"d\"] = round(latex_df.d) + latex_df.sig.astype(str)\n",
    "latex_df[\"p\"] = round(latex_df.p, i='{0:0.3f}')\n",
    "latex_df = latex_df.drop(columns=[\"sig\"])\n",
    "latex_df.columns = [f\"${col}$\" for col in latex_df.columns]\n",
    "\n",
    "def models(df, *keys):\n",
    "    return df.index.get_level_values(\"Model\").isin(keys)\n",
    "\n",
    "# main results\n",
    "main_experiment = latex_df.index.get_level_values(\"Test\").isin(experiments)\n",
    "intersectional = latex_df.index.get_level_values(\"Test\").str.contains(\"Intersectional\")\n",
    "latex_df[main_experiment & ~intersectional]\\\n",
    "    .drop(columns=[\"$X$\", \"$Y$\", \"$A$\", \"$B$\"]).to_latex('output/results.tex', escape=False)\n",
    "# intersectional results\n",
    "latex_df[main_experiment & intersectional & models(latex_df, \"igpt\", \"simclr\")]\\\n",
    "    .to_latex('output/intersectional.tex', escape=False)\n",
    "# table of iats w/ categories\n",
    "latex_df.droplevel(\"Model\").groupby(\"Test\").head(1)\\\n",
    "    .drop(columns=[\"$d$\", \"$p$\", \"$n_t$\", \"$n_a$\"]).to_latex('output/iats.tex', escape=False)\n",
    "stimuli = pd.read_csv(\"data/stimuli.csv\")\n",
    "stimuli.dropna(axis=0, subset=[\"Word\", \"Source\"])\\\n",
    "    .drop(columns=\"Collected (N=n)\").set_index([\"IAT\", \"Category\"]).to_latex(\"output/stimuli.tex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WH3YS_ytSHSw"
   },
   "source": [
    "### Detail View"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ePsWzNWpiTI"
   },
   "source": [
    "#### Weapons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xF-vbLVkWSLo"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/weapon/black\",\n",
    "    \"data/experiments/weapon/white\",\n",
    "    \"data/experiments/weapon/tool\",\n",
    "    \"data/experiments/weapon/weapon\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px\n",
    "#     from_cache=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbZZ-m6QpiTM"
   },
   "source": [
    "#### Native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wTs4pDDwpiTM"
   },
   "outputs": [],
   "source": [
    "test(\n",
    "    \"data/experiments/native/euro\",\n",
    "    \"data/experiments/native/native\",\n",
    "    \"data/experiments/native/us\",\n",
    "    \"data/experiments/native/world\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px\n",
    "#     from_cache=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyrLx0cmpiTO"
   },
   "source": [
    "#### Asian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_nEjOV-QpiTP"
   },
   "outputs": [],
   "source": [
    "test(\n",
    "    \"data/experiments/asian/european-american\",\n",
    "    \"data/experiments/asian/asian-american\",\n",
    "    \"data/experiments/asian/american\",\n",
    "    \"data/experiments/asian/foreign\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px\n",
    "#     from_cache=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8Wpc7vPxvhZ"
   },
   "source": [
    "#### Insect-Flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_dzK41F6Hso"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/insect-flower/flower\",\n",
    "    \"data/experiments/insect-flower/insect\",\n",
    "    \"data/experiments/valence/pleasant\",\n",
    "    \"data/experiments/valence/unpleasant\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZalmenA0xvhb"
   },
   "source": [
    "#### Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ziXl8gaWxvhc"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/weight/thin\",\n",
    "    \"data/experiments/weight/fat\",\n",
    "    \"data/experiments/valence/pleasant\",\n",
    "    \"data/experiments/valence/unpleasant\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gYnQK4vxvhe"
   },
   "source": [
    "#### Skin-Tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VFg-zm4Ixvhe"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/skin-tone/light\",\n",
    "    \"data/experiments/skin-tone/dark\",\n",
    "    \"data/experiments/valence/pleasant\",\n",
    "    \"data/experiments/valence/unpleasant\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqoUJ9_oxvhh"
   },
   "source": [
    "#### Disability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nLLGZcCRxvhh"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/disabled/disabled\",\n",
    "    \"data/experiments/disabled/abled\",\n",
    "    \"data/experiments/valence/pleasant\",\n",
    "    \"data/experiments/valence/unpleasant\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VX-5Fpk2xvhl"
   },
   "source": [
    "#### Presidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qPYAHFFGxvhm"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/presidents/trump\",\n",
    "    \"data/experiments/presidents/kennedy\",\n",
    "    \"data/experiments/valence/pleasant\",\n",
    "    \"data/experiments/valence/unpleasant\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqSZmD4Rxvho"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/presidents/trump\",\n",
    "    \"data/experiments/presidents/clinton\",\n",
    "    \"data/experiments/valence/pleasant\",\n",
    "    \"data/experiments/valence/unpleasant\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L6HNE0bvxvhq"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/presidents/trump\",\n",
    "    \"data/experiments/presidents/bush\",\n",
    "    \"data/experiments/valence/pleasant\",\n",
    "    \"data/experiments/valence/unpleasant\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oTOxt8Y5xvhs"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/presidents/trump\",\n",
    "    \"data/experiments/presidents/lincoln\",\n",
    "    \"data/experiments/valence/pleasant\",\n",
    "    \"data/experiments/valence/unpleasant\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ErIbgFMXxvhu"
   },
   "source": [
    "#### Religion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VvAe-DuUxvhu"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/religion/christianity\",\n",
    "    \"data/experiments/religion/judaism\",\n",
    "    \"data/experiments/valence/pleasant\",\n",
    "    \"data/experiments/valence/unpleasant\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gt3GfXoYxvhw"
   },
   "source": [
    "#### Gender-Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2zs-M-ezxvhx"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/gender/science\",\n",
    "    \"data/experiments/gender/liberal-arts\",\n",
    "    \"data/experiments/gender/male\",\n",
    "    \"data/experiments/gender/female\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXbraCTvxvhy"
   },
   "source": [
    "#### Gender-Career"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wmICFKRhxvhz"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/gender/career\",\n",
    "    \"data/experiments/gender/family\",\n",
    "    \"data/experiments/gender/male\",\n",
    "    \"data/experiments/gender/female\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BI1Gxc4xvh1"
   },
   "source": [
    "#### Sexuality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6qhiTy3Rxvh2"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/sexuality/gay\",\n",
    "    \"data/experiments/sexuality/straight\",\n",
    "    \"data/experiments/valence/pleasant\",\n",
    "    \"data/experiments/valence/unpleasant\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VIIIFfpxvh3"
   },
   "source": [
    "#### Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fSuQzadOxvh4"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/race/african-american\",\n",
    "    \"data/experiments/race/european-american\",\n",
    "    \"data/experiments/valence/pleasant\",\n",
    "    \"data/experiments/valence/unpleasant\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xA_AwxiKxvh5"
   },
   "source": [
    "#### Arab-Muslim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dAvppwCJxvh6"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/arab-muslim/other-people\",\n",
    "    \"data/experiments/arab-muslim/arab-muslim\",\n",
    "    \"data/experiments/valence/pleasant\",\n",
    "    \"data/experiments/valence/unpleasant\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-fdCFqQxvh8"
   },
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVB-Wne_xvh8"
   },
   "outputs": [],
   "source": [
    "from ieat.api import test\n",
    "\n",
    "test(\n",
    "    \"data/experiments/age/young\",\n",
    "    \"data/experiments/age/old\",\n",
    "    \"data/experiments/valence/pleasant\",\n",
    "    \"data/experiments/valence/unpleasant\",\n",
    "    model_type=\"openai\", \n",
    "    model_size=model_size,\n",
    "    models_dir=models_dir,\n",
    "    clusters_dir=color_clusters_dir,\n",
    "    n_px=n_px,\n",
    "#     from_cache=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpKVucUpxvh-"
   },
   "source": [
    "### Download Cached Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EfMcw700xvh-"
   },
   "outputs": [],
   "source": [
    "# to download from colab\n",
    "from google.colab import files\n",
    "\n",
    "!zip -r embeddings_colab.zip embeddings\n",
    "files.download(\"embeddings_colab.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GnG7quNVxviA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Image-GPT-Bias-HuggingFace.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "require": {
   "paths": {
    "buttons.colvis": "https://cdn.datatables.net/buttons/1.5.6/js/buttons.colVis.min",
    "buttons.flash": "https://cdn.datatables.net/buttons/1.5.6/js/buttons.flash.min",
    "buttons.html5": "https://cdn.datatables.net/buttons/1.5.6/js/buttons.html5.min",
    "buttons.print": "https://cdn.datatables.net/buttons/1.5.6/js/buttons.print.min",
    "chartjs": "https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.8.0/Chart",
    "d3": "https://d3js.org/d3.v5.min",
    "d3-array": "https://d3js.org/d3-array.v2.min",
    "datatables.net": "https://cdn.datatables.net/1.10.18/js/jquery.dataTables",
    "datatables.net-buttons": "https://cdn.datatables.net/buttons/1.5.6/js/dataTables.buttons.min",
    "datatables.responsive": "https://cdn.datatables.net/responsive/2.2.2/js/dataTables.responsive.min",
    "datatables.scroller": "https://cdn.datatables.net/scroller/2.0.0/js/dataTables.scroller.min",
    "datatables.select": "https://cdn.datatables.net/select/1.3.0/js/dataTables.select.min",
    "jszip": "https://cdnjs.cloudflare.com/ajax/libs/jszip/2.5.0/jszip.min",
    "moment": "https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.8.0/moment",
    "pdfmake": "https://cdnjs.cloudflare.com/ajax/libs/pdfmake/0.1.36/pdfmake.min",
    "vfsfonts": "https://cdnjs.cloudflare.com/ajax/libs/pdfmake/0.1.36/vfs_fonts"
   },
   "shim": {
    "buttons.colvis": {
     "deps": [
      "jszip",
      "datatables.net-buttons"
     ]
    },
    "buttons.flash": {
     "deps": [
      "jszip",
      "datatables.net-buttons"
     ]
    },
    "buttons.html5": {
     "deps": [
      "jszip",
      "datatables.net-buttons"
     ]
    },
    "buttons.print": {
     "deps": [
      "jszip",
      "datatables.net-buttons"
     ]
    },
    "chartjs": {
     "deps": [
      "moment"
     ]
    },
    "datatables.net": {
     "exports": "$.fn.dataTable"
    },
    "datatables.net-buttons": {
     "deps": [
      "datatables.net"
     ]
    },
    "pdfmake": {
     "deps": [
      "datatables.net"
     ]
    },
    "vfsfonts": {
     "deps": [
      "datatables.net"
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
